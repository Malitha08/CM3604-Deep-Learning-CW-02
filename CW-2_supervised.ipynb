{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding necessary import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target values\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target values\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Function to prepare the pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = prep_pixels(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_per_class(yd):\n",
    "    ydf = pd.DataFrame(yd)\n",
    "    f, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "    g = sns.countplot(ydf[0], order = np.arange(0,10))\n",
    "    g.set_title(\"Number of items for each class\")\n",
    "    g.set_xlabel(\"Category\")\n",
    "    \n",
    "    for p, label in zip(g.patches, np.arange(0,10)):\n",
    "        g.annotate(labels[label], (p.get_x(), p.get_height()+0.1))\n",
    "        \n",
    "    plt.show()  \n",
    "\n",
    "def get_count_per_class(yd):\n",
    "    ydf = pd.DataFrame(yd)\n",
    "    # Get the count for each label\n",
    "    label_counts = ydf[0].value_counts()\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(yd)\n",
    "\n",
    "\n",
    "    # Count the number of items in each class\n",
    "    for i in range(len(label_counts)):\n",
    "        label = labels[label_counts.index[i]]\n",
    "        count = label_counts.values[i]\n",
    "        percent = (count / total_samples) * 100\n",
    "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
    "    \n",
    "plot_count_per_class(np.argmax(y_train,axis=1))\n",
    "get_count_per_class(np.argmax(y_train,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_per_class(np.argmax(y_test,axis=1))\n",
    "get_count_per_class(np.argmax(y_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model.fit(x_train, y_train,\n",
    "                  batch_size=128,\n",
    "                  epochs=50,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # get summary of cmpiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduce test loss and accuracy\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions for creating relevant plots for Epoch vs Accuray & Epoch vs loss\n",
    "\n",
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    \n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "   \n",
    "    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "\n",
    "    \n",
    "    iplot(fig, filename='accuracy-loss')\n",
    "\n",
    "plot_accuracy_and_loss(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # define model\n",
    "        model = train_model\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # append scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Jun 27 2022, 23:25:00) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d8408dc480075e2039c6acca2bc3a233d5b259cada6abff183c4b20726df9f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
