{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding necessary import\n",
    "\n",
    "import sklearn\n",
    "import keras\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, normalized_mutual_info_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "(x_train, y_train),(x_test, y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "x=np.concatenate((x_train, x_test))\n",
    "y=np.concatenate((y_train, y_test))\n",
    "print(x.shape)\n",
    "x=x_train.reshape((x_train.shape[0],-1))\n",
    "x=np.divide(x.astype(float),255)\n",
    "kmeans = KMeans(n_clusters = 10)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means labeling \n",
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    inferred_labels = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "        labels.append(actual_labels[index])\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            inferred_labels[np.argmax(counts)] = [i]      \n",
    "    return inferred_labels  \n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "                \n",
    "    return predicted_labels\n",
    "    \n",
    "n_clusters=10\n",
    "cluster_labels = infer_cluster_labels(kmeans, y_train)\n",
    "X_clusters = kmeans.predict(x)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "print(predicted_labels[:20])\n",
    "print(y_train[:20])\n",
    "from sklearn import metrics\n",
    "# evaluation of kmeans\n",
    "def calculate_metrics(estimator, data, labels):   \n",
    "    print('Homogeneity: {}'.format(metrics.homogeneity_score(labels, estimator.labels_)))\n",
    "    print('Inertia: {}'.format(estimator.inertia_))\n",
    "    print('Number of Clusters: {}'.format(estimator.n_clusters))\n",
    "    \n",
    "    \n",
    "clusters = [10]\n",
    "for n_clusters in clusters:\n",
    "    estimator = MiniBatchKMeans(n_clusters = n_clusters)\n",
    "    estimator.fit(x)\n",
    "    calculate_metrics(estimator, x, y_train)\n",
    "    cluster_labels = infer_cluster_labels(estimator, y_train)\n",
    "    predicted_Y = infer_data_labels(estimator.labels_, cluster_labels)\n",
    "    print('KMeans Accuracy: {}\\n'.format(metrics.accuracy_score(y_train, predicted_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the \n",
    "x_train=x_train.reshape(-1,28,28,1)/255\n",
    "x_test=x_test.reshape(-1,28,28,1)/255\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto Encoder using K-Means clustering\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Conv2D(14, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D((2,2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(7, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((2,2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(7, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(14, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(UpSampling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(1, kernel_size=3, padding='same', activation='relu'))\n",
    "model.compile(optimizer=SGD(0.01,0.9), loss=\"mse\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_AE=model.fit(x_train, x_train, epochs=10, batch_size=256, validation_data=(x_validate, x_validate), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossPlot():\n",
    "    trainingLoss,=plt.plot(history_AE.history['loss'],\"r--\")\n",
    "    validationLoss,=plt.plot(history_AE.history['val_loss'],\"b--\")\n",
    "    q=plt.legend([trainingLoss,validationLoss],[\"Training Loss\",\"Validation Loss\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss & Validation Loss vs Number of Epochs Graph\")\n",
    "    plt.show()\n",
    "lossPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = K.function([model.layers[0].input], [model.layers[4].output])\n",
    "encoded_images = encoder([x_test])[0].reshape(-1,7*7*7)\n",
    "kmeans_afterencoder_AE = KMeans(n_clusters=10)\n",
    "clustered_set_AE = kmeans_afterencoder_AE.fit_predict(encoded_images)\n",
    "cmKMeans = confusion_matrix(y_test, clustered_set_AE)\n",
    "print(cmKMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_afterencoder_AE.fit(encoded_images)\n",
    "calculate_metrics(kmeans_afterencoder_AE, encoded_images, y_test)\n",
    "cluster_labels_AE = infer_cluster_labels(kmeans_afterencoder_AE, y_test)\n",
    "predicted_Y_AE = infer_data_labels(kmeans_afterencoder_AE.labels_, cluster_labels_AE)\n",
    "print('Auto Encoder using K-Means clustering Accuracy: {}\\n'.format(metrics.accuracy_score(y_test, predicted_Y_AE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Mixture Model\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=10)\n",
    "gmm.fit(encoded_images)\n",
    "labelsGMM=gmm.predict(encoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels_GMM(gmm, actual_labels):\n",
    "    inferred_labels = {}\n",
    "    for i in range(gmm.n_components):\n",
    "        labels = []\n",
    "        index = np.where(labelsGMM == i)\n",
    "        labels.append(actual_labels[index])\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "    return inferred_labels  \n",
    "    \n",
    "def infer_data_labels_GMM(X_labels, cluster_labels):\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key                \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_GMM = infer_cluster_labels_GMM(gmm, y_test)\n",
    "predicted_Y_GMM = infer_data_labels_GMM(labelsGMM, cluster_labels_GMM)\n",
    "print('Gaussian Mixture Model Clustering Accuracy: {}\\n'.format(metrics.accuracy_score(y_test, predicted_Y_GMM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix_GMM = confusion_matrix(y_test, labelsGMM)\n",
    "print(confusionmatrix_GMM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e591c5c7041cf022b0789e00d8f98911e279a6ab611d5520dacfd51e0217e576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
